{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1 id=\"header-ch\">2021 CCF BDCI基于飞桨实现花样滑冰选手骨骼点动作识别-第6名方案</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 赛题介绍\n",
    "\n",
    "人体运动分析是近几年许多领域研究的热点问题。在学科的交叉研究上，人体运动分析涉及到计算机科学、运动人体科学、环境行为学和材料科学等。随着研究的深入以及计算机视觉、5G通信的飞速发展，人体运动分析技术已应用于自动驾驶、影视创作、安防异常事件监测和体育竞技分析、康复等实际场景人体运动分析已成为人工智能领域研究的前沿课题。目前的研究数据普遍缺少细粒度语义信息，导致现存的分割或识别任务缺少时空细粒度动作语义模型。此类研究在竞技体育、运动康复、日常健身等方面有非常重大的意义。相比于图片的细粒度研究，时空细粒度语义的人体动作具有动作的类内方差大、类间方差小这一特点，这将导致由细粒度语义产生的一系列问题，利用粗粒度语义的识别模型进行学习难得获得理想的结果。\n",
    "\n",
    "基于实际需求以及图深度学习模型的发展，本比赛旨在构建基于骨骼点的细粒度人体动作识别方法。通过本赛题建立精度高、细粒度意义明确的动作识别模型，希望大家探索时空细粒度模型的新方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RES2CTR-GCN介绍\n",
    "\n",
    "## 整体结构\n",
    "\n",
    "本算法是基于[CTR-GCN](https://arxiv.org/pdf/2107.12213v2.pdf)进行改进，采用多流同结构算法整体框架如下图所示：\n",
    "### 双流算法流程图\n",
    "<p align=\"center\">\n",
    " <img src=\"multi_stream.png\" width = \"500\" height = \"50\" alt=\"\" align=\"center\" />\n",
    "\n",
    "  ### 单流算法流程图\n",
    "<p align=\"center\">\n",
    " <img src=\"model.png\" width = \"500\" height = \"50\" alt=\"\" align=\"center\" />\n",
    "\n",
    "### RES2CTR-GCN模块\n",
    "\n",
    " <img src=\"RES2CTR-GCN.png\" width = \"500\" height = \"50\" alt=\"\" align=\"center\" />\n",
    " <img src=\"CTR-GC.png\" width = \"500\" height = \"50\" alt=\"\" align=\"center\" />\n",
    " <img src=\"TEMORAL_MODELING.png\" width = \"500\" height = \"50\" alt=\"\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据增强/清洗策略\n",
    "\n",
    "### 数据流的构建\n",
    "\n",
    "本模型采用多流同结构 故需要对训练的数据流以及预测的数据流进行预先的构建。构建的代码在data文件夹下的get_data.py\n",
    "\n",
    "### 数据增强\n",
    "在训练的情况下,采用mixup数据增强的策略,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## AI模型开发过程、训练技巧、创新思路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 下载githee模型代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n",
      "Cloning into 'ccf'...\n",
      "remote: Enumerating objects: 665, done.\u001b[K\n",
      "remote: Counting objects: 100% (665/665), done.\u001b[K\n",
      "remote: Compressing objects: 100% (563/563), done.\u001b[K\n",
      "remote: Total 665 (delta 171), reused 481 (delta 87), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (665/665), 79.44 MiB | 13.43 MiB/s, done.\n",
      "Resolving deltas: 100% (171/171), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# 进入到gitclone 的 ccf 目录下\r\n",
    "%cd ~/work/\r\n",
    "!git clone https://gitee.com/mark_twain/ccf.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  配置代码环境，安装相应的依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7MB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.2.3\n",
      "    Uninstalling pip-19.2.3:\n",
      "      Successfully uninstalled pip-19.2.3\n",
      "Successfully installed pip-21.3.1\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.16.4)\n",
      "Collecting numpy\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5b/0d/de55834c5ea0dd287cb1cb156c8bc120af2863c36e4d49b4dc28f174e278/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.1.5)\n",
      "Collecting pandas\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/0f/118a4201f552e2b6adb63cfcde4d16c7b3ae545490d4107a9265e8462db8/pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     |████████████████████████████████| 11.3 MB 5.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (4.36.1)\n",
      "Collecting tqdm\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/63/f3/b7a1b8e40fd1bd049a34566eb353527bb9b8e9b98f8b6cf803bb64d8ce95/tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (5.1.2)\n",
      "Collecting PyYAML>=5.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting opencv-python==4.2.0.32\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/34/a3/403dbaef909fee9f9f6a8eaff51d44085a14e5bb1a1ff7257117d744986a/opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (28.2 MB)\n",
      "Collecting decord==0.4.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c0/0c/7d99cfcde7b85f80c9ea9b0b19441339ad3cef59ee7fa5386598db714efe/decord-0.4.2-py2.py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting av==8.0.3\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n",
      "Installing collected packages: numpy, tqdm, PyYAML, pandas, opencv-python, decord, av\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.1.2\n",
      "    Uninstalling PyYAML-5.1.2:\n",
      "      Successfully uninstalled PyYAML-5.1.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.1.1.26\n",
      "    Uninstalling opencv-python-4.1.1.26:\n",
      "      Successfully uninstalled opencv-python-4.1.1.26\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blackhole 1.0.1 requires numpy<=1.19.5, but you have numpy 1.21.4 which is incompatible.\n",
      "blackhole 1.0.1 requires pandas<=1.1.5,>=0.24.0, but you have pandas 1.3.4 which is incompatible.\u001b[0m\n",
      "Successfully installed PyYAML-6.0 av-8.0.3 decord-0.4.2 numpy-1.21.4 opencv-python-4.2.0.32 pandas-1.3.4 tqdm-4.62.3\n"
     ]
    }
   ],
   "source": [
    "!python3.7 -m pip install --upgrade pip\r\n",
    "!python3.7 -m pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 解压数据集并将数据集移动到指定文件夹中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "Archive:  data/data118075/bdcidataset.zip\n",
      "  inflating: test_A_data.npy         \n",
      "  inflating: test_B_data.npy         \n",
      "  inflating: train_label.npy         \n",
      "  inflating: train_data.npy          \n"
     ]
    }
   ],
   "source": [
    "# 将数据集解压\r\n",
    "%cd ~/\r\n",
    "!unzip data/data118075/bdcidataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将数据集移动到代码文件ccf/data中\r\n",
    "!mv test_A_data.npy ./work/ccf/data/\r\n",
    "!mv test_B_data.npy ./work/ccf/data/\r\n",
    "!mv train_label.npy ./work/ccf/data/\r\n",
    "!mv train_data.npy ./work/ccf/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/ccf\n"
     ]
    }
   ],
   "source": [
    "# 进入到gitclone 的ccf目录下\n",
    "%cd ~/work/ccf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 配置文件\n",
    "\n",
    "由于是本模型是采用三流同结构算法 故有3个不同的配置文件以配置不同的输入流\n",
    "\n",
    "三个配置文件分别为：\n",
    "`configs/recognition/ctrgcn/res2ctrgcn_keypoint_bone.yaml`\n",
    "\n",
    "`configs/recognition/ctrgcn/res2ctrgcn_keypoint_joint.yaml`\n",
    "\n",
    "`configs/recognition/ctrgcn/res2ctrgcn_keypoint_velocity.yaml`\n",
    "\n",
    "\n",
    "### 以`configs/recognition/ctrgcn/res2ctrgcn_keypoint_bone.yaml`为例子的配置文件的内容\n",
    "通过yaml配置文件的方式选择不同的算法和训练参数等，这里我们使用`configs/recognition/ctrgcn/res2ctrgcn_keypoint_bone.yaml`配置文件完成RES2CTR-GCN模型算法训练。从该配置文件中，我们可以得到如下信息：\n",
    "\n",
    "### 网络结构\n",
    "```yaml\n",
    "MODEL: \n",
    "    framework: \"RecognizerGCN\" \n",
    "    backbone: \n",
    "        name: \"RES2CTRGCN\"\n",
    "    head:\n",
    "        name: \"CTRGCNHead\" \n",
    "        num_classes: 30\n",
    "```\n",
    "\n",
    "表示我们使用的是RES2CTR-GCN算法，framework为`RecognizerGCN`，backbone是时空图卷积网络`RES2CTR-GCN`，head使用对应的`CTRGCNHead`，采用soft-label计算损失函数，损失函数是`CrossEntropyLoss`。\n",
    "\n",
    "\n",
    "### 数据路径\n",
    "\n",
    "```yaml\n",
    "DATASET: \n",
    "    batch_size: 8 \n",
    "    num_workers: 4 \n",
    "    test_batch_size: 1\n",
    "    test_num_workers: 0\n",
    "    train:\n",
    "        format: \"SkeletonDataset\" \n",
    "        file_path: \"data/train_bone_data.npy\"    # 手动配置\n",
    "        label_path: \"data/train_label.npy\"  # 手动配置\n",
    "    test:\n",
    "        format: \"SkeletonDataset\" \n",
    "        file_path: \"data/test_bone_B_data.npy\"   # 手动配置\n",
    "        test_mode: True\n",
    "```\n",
    "\n",
    "训练数据路径通过`DATASET.train.file_path`字段指定，训练标签路径通过`DATASET.train.label_path`字段指定，测试数据路径通过`DATASET.test.file_path`字段指定。这三个路径**需要用户在配置文件`configs/recognition/ctrgcn/res2ctrgcn_keypoint_joint.yaml`中手动配置好**。本项目中路径示例如上所示。\n",
    "\n",
    "### 数据处理\n",
    "\n",
    "```yaml\n",
    "PIPELINE: \n",
    "    train: \n",
    "        sample:\n",
    "            name: \"SampleFrame\"\n",
    "            window_size: 2000\n",
    "        transform: \n",
    "            - SkeletonNorm:\n",
    "    test: \n",
    "        sample:\n",
    "            name: \"SampleFrame\"\n",
    "            window_size: 2000\n",
    "        transform: \n",
    "            - SkeletonNorm:\n",
    "```\n",
    "\n",
    "数据处理主要包括两步操作，分别为`SampleFrame`和`SkeletonNorm`。\n",
    "\n",
    "### 优化器\n",
    "\n",
    "```yaml\n",
    "OPTIMIZER: #OPTIMIZER field\n",
    "  name: 'Momentum'\n",
    "  momentum: 0.9\n",
    "  learning_rate:\n",
    "    iter_step: True\n",
    "    name: 'CustomWarmupCosineDecay'\n",
    "    max_epoch: 100\n",
    "    warmup_epochs: 10\n",
    "    warmup_start_lr: 0.005\n",
    "    cosine_base_lr: 0.1\n",
    "```\n",
    "\n",
    "网络训练使用的优化器为`Momentum`，学习率更新策略为`CustomWarmupCosineDecay`。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一键启动训练脚本\n",
    "### 运行脚本指令\n",
    "```bash\n",
    "bash train.sh\n",
    "```\n",
    "\n",
    "你将会看到类似如下的训练日志\n",
    "```txt\n",
    "[11/14 13:47:39] \u001b[35mepoch:[  1/100]\u001b[0m \u001b[95mtrain step:0   \u001b[0m \u001b[92mloss: 3.45860 lr: 0.005000 top1: 0.11111 top5: 0.11111\u001b[0m \u001b[92mbatch_cost: 2.37207 sec,\u001b[0m \u001b[92mreader_cost: 0.15600 sec,\u001b[0m ips: 3.79416 instance/sec.\n",
    "[11/14 13:47:48] epoch:[  1/100] \u001b[95mtrain step:10  \u001b[0m \u001b[92mloss: 3.21713 lr: 0.005286 top1: 0.00000 top5: 0.42159\u001b[0m \u001b[92mbatch_cost: 0.96801 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.29743 instance/sec.\n",
    "[11/14 13:47:58] epoch:[  1/100] \u001b[95mtrain step:20  \u001b[0m \u001b[92mloss: 3.16619 lr: 0.005571 top1: 0.21693 top5: 0.32804\u001b[0m \u001b[92mbatch_cost: 0.98901 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.10002 instance/sec.\n",
    "[11/14 13:48:08] epoch:[  1/100] \u001b[95mtrain step:30  \u001b[0m \u001b[92mloss: 2.65808 lr: 0.005857 top1: 0.22222 top5: 0.55555\u001b[0m \u001b[92mbatch_cost: 0.95300 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.44386 instance/sec.\n",
    "[11/14 13:48:17] epoch:[  1/100] \u001b[95mtrain step:40  \u001b[0m \u001b[92mloss: 2.95422 lr: 0.006143 top1: 0.00000 top5: 0.49274\u001b[0m \u001b[92mbatch_cost: 0.92300 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.75082 instance/sec.\n",
    "[11/14 13:48:27] epoch:[  1/100] \u001b[95mtrain step:50  \u001b[0m \u001b[92mloss: 3.37573 lr: 0.006428 top1: 0.07475 top5: 0.29899\u001b[0m \u001b[92mbatch_cost: 0.92377 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.74270 instance/sec.\n",
    "[11/14 13:48:36] epoch:[  1/100] \u001b[95mtrain step:60  \u001b[0m \u001b[92mloss: 2.69240 lr: 0.006714 top1: 0.33333 top5: 0.58678\u001b[0m \u001b[92mbatch_cost: 0.91400 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.84682 instance/sec.\n",
    "[11/14 13:48:46] epoch:[  1/100] \u001b[95mtrain step:70  \u001b[0m \u001b[92mloss: 2.88237 lr: 0.007000 top1: 0.00000 top5: 0.53872\u001b[0m \u001b[92mbatch_cost: 0.91900 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.79326 instance/sec.\n",
    "[11/14 13:48:55] epoch:[  1/100] \u001b[95mtrain step:80  \u001b[0m \u001b[92mloss: 3.31014 lr: 0.007285 top1: 0.11111 top5: 0.44141\u001b[0m \u001b[92mbatch_cost: 0.95794 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.39519 instance/sec.\n",
    "[11/14 13:49:05] epoch:[  1/100] \u001b[95mtrain step:90  \u001b[0m \u001b[92mloss: 2.97485 lr: 0.007571 top1: 0.11111 top5: 0.55454\u001b[0m \u001b[92mbatch_cost: 0.99122 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.07971 instance/sec.\n",
    "[11/14 13:49:15] epoch:[  1/100] \u001b[95mtrain step:100 \u001b[0m \u001b[92mloss: 3.22369 lr: 0.007857 top1: 0.00000 top5: 0.42589\u001b[0m \u001b[92mbatch_cost: 1.02620 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 8.77022 instance/sec.\n",
    "[11/14 13:49:24] epoch:[  1/100] \u001b[95mtrain step:110 \u001b[0m \u001b[92mloss: 2.41740 lr: 0.008142 top1: 0.52294 top5: 0.83453\u001b[0m \u001b[92mbatch_cost: 0.98703 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.11828 instance/sec.\n",
    "[11/14 13:49:34] epoch:[  1/100] \u001b[95mtrain step:120 \u001b[0m \u001b[92mloss: 2.87388 lr: 0.008428 top1: 0.00000 top5: 0.62665\u001b[0m \u001b[92mbatch_cost: 0.93400 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.63598 instance/sec.\n",
    "[11/14 13:49:43] epoch:[  1/100] \u001b[95mtrain step:130 \u001b[0m \u001b[92mloss: 2.71671 lr: 0.008714 top1: 0.33333 top5: 0.73594\u001b[0m \u001b[92mbatch_cost: 1.01655 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 8.85346 instance/sec.\n",
    "[11/14 13:49:53] epoch:[  1/100] \u001b[95mtrain step:140 \u001b[0m \u001b[92mloss: 2.67541 lr: 0.008999 top1: 0.33332 top5: 0.77776\u001b[0m \u001b[92mbatch_cost: 0.91100 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.87926 instance/sec.\n",
    "[11/14 13:50:02] epoch:[  1/100] \u001b[95mtrain step:150 \u001b[0m \u001b[92mloss: 3.34374 lr: 0.009285 top1: 0.00000 top5: 0.40388\u001b[0m \u001b[92mbatch_cost: 0.92400 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.74027 instance/sec.\n",
    "[11/14 13:50:11] epoch:[  1/100] \u001b[95mtrain step:160 \u001b[0m \u001b[92mloss: 3.10928 lr: 0.009571 top1: 0.11111 top5: 0.55556\u001b[0m \u001b[92mbatch_cost: 0.92956 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.68198 instance/sec.\n",
    "[11/14 13:50:21] epoch:[  1/100] \u001b[95mtrain step:170 \u001b[0m \u001b[92mloss: 3.18118 lr: 0.009856 top1: 0.00000 top5: 0.55554\u001b[0m \u001b[92mbatch_cost: 0.92963 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.68124 instance/sec.\n",
    "[11/14 13:50:30] epoch:[  1/100] \u001b[95mtrain step:180 \u001b[0m \u001b[92mloss: 2.78696 lr: 0.010142 top1: 0.33303 top5: 0.66576\u001b[0m \u001b[92mbatch_cost: 0.92700 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.70872 instance/sec.\n",
    "[11/14 13:50:39] epoch:[  1/100] \u001b[95mtrain step:190 \u001b[0m \u001b[92mloss: 3.06701 lr: 0.010427 top1: 0.22962 top5: 0.52839\u001b[0m \u001b[92mbatch_cost: 0.93000 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.67740 instance/sec.\n",
    "[11/14 13:50:48] epoch:[  1/100] \u001b[95mtrain step:200 \u001b[0m \u001b[92mloss: 2.81732 lr: 0.010713 top1: 0.00000 top5: 0.66872\u001b[0m \u001b[92mbatch_cost: 0.92860 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.69201 instance/sec.\n",
    "[11/14 13:50:58] epoch:[  1/100] \u001b[95mtrain step:210 \u001b[0m \u001b[92mloss: 2.74136 lr: 0.010999 top1: 0.22222 top5: 0.68260\u001b[0m \u001b[92mbatch_cost: 0.93100 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.66704 instance/sec.\n",
    "[11/14 13:51:07] epoch:[  1/100] \u001b[95mtrain step:220 \u001b[0m \u001b[92mloss: 3.03122 lr: 0.011284 top1: 0.19732 top5: 0.44444\u001b[0m \u001b[92mbatch_cost: 0.95900 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.38478 instance/sec.\n",
    "[11/14 13:51:16] epoch:[  1/100] \u001b[95mtrain step:230 \u001b[0m \u001b[92mloss: 2.72677 lr: 0.011570 top1: 0.21040 top5: 0.60753\u001b[0m \u001b[92mbatch_cost: 0.92000 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.78263 instance/sec.\n",
    "[11/14 13:51:26] epoch:[  1/100] \u001b[95mtrain step:240 \u001b[0m \u001b[92mloss: 2.53266 lr: 0.011856 top1: 0.42706 top5: 0.64349\u001b[0m \u001b[92mbatch_cost: 0.92751 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.70338 instance/sec.\n",
    "[11/14 13:51:35] epoch:[  1/100] \u001b[95mtrain step:250 \u001b[0m \u001b[92mloss: 2.67476 lr: 0.012141 top1: 0.11108 top5: 0.77764\u001b[0m \u001b[92mbatch_cost: 0.93000 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.67742 instance/sec.\n",
    "[11/14 13:51:44] epoch:[  1/100] \u001b[95mtrain step:260 \u001b[0m \u001b[92mloss: 2.96337 lr: 0.012427 top1: 0.09552 top5: 0.52438\u001b[0m \u001b[92mbatch_cost: 0.93500 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.62569 instance/sec.\n",
    "[11/14 13:51:53] epoch:[  1/100] \u001b[95mtrain step:270 \u001b[0m \u001b[92mloss: 3.01553 lr: 0.012713 top1: 0.22222 top5: 0.66056\u001b[0m \u001b[92mbatch_cost: 0.91700 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.81461 instance/sec.\n",
    "[11/14 13:52:03] epoch:[  1/100] \u001b[95mtrain step:280 \u001b[0m \u001b[92mloss: 3.02630 lr: 0.012998 top1: 0.22222 top5: 0.51143\u001b[0m \u001b[92mbatch_cost: 0.91700 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.81463 instance/sec.\n",
    "[11/14 13:52:12] epoch:[  1/100] \u001b[95mtrain step:290 \u001b[0m \u001b[92mloss: 2.64080 lr: 0.013284 top1: 0.10819 top5: 0.65205\u001b[0m \u001b[92mbatch_cost: 0.93278 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 9.64855 instance/sec.\n",
    "[11/14 13:52:21] epoch:[  1/100] \u001b[95mtrain step:300 \u001b[0m \u001b[92mloss: 2.56226 lr: 0.013570 top1: 0.33230 top5: 0.77640\u001b[0m \u001b[92mbatch_cost: 0.92300 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.75082 instance/sec.\n",
    "[11/14 13:52:30] epoch:[  1/100] \u001b[95mtrain step:310 \u001b[0m \u001b[92mloss: 2.31375 lr: 0.013855 top1: 0.21937 top5: 0.87747\u001b[0m \u001b[92mbatch_cost: 0.91700 sec,\u001b[0m \u001b[92mreader_cost: 0.00100 sec,\u001b[0m ips: 9.81463 instance/sec.\n",
    "[11/14 13:52:40] epoch:[  1/100] \u001b[95mtrain step:320 \u001b[0m \u001b[92mloss: 2.93230 lr: 0.014141 top1: 0.11111 top5: 0.44344\u001b[0m \u001b[92mbatch_cost: 0.88833 sec,\u001b[0m \u001b[92mreader_cost: 0.00000 sec,\u001b[0m ips: 10.13133 instance/sec.\n",
    "[11/14 13:52:42] [31mEND epoch:1  [0m [95mtrain\u001b[0m \u001b[92mloss_avg: 2.93599  top1_avg: 0.14609 top5_avg: 0.56468\u001b[0m \u001b[92mavg_batch_cost: 0.93686 sec,\u001b[0m \u001b[92mavg_reader_cost: 0.00000 sec,\u001b[0m \u001b[92mbatch_cost_sum: 305.87457 sec,\u001b[0m avg_ips: 9.53332 instance/sec.\n",
    "```\n",
    "\n",
    "#### 注意事项\n",
    "请使用<span style='color:red'>GPU版本</span>的配置环境运行本模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting numpy (from -r requirements.txt (line 1))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5b/0d/de55834c5ea0dd287cb1cb156c8bc120af2863c36e4d49b4dc28f174e278/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting pandas (from -r requirements.txt (line 2))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/58/58/b729eda34f78060e14cb430c91d4f7ba3cf1e34797976877a3a1125ea5b2/pandas-1.3.4.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 3))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/63/f3/b7a1b8e40fd1bd049a34566eb353527bb9b8e9b98f8b6cf803bb64d8ce95/tqdm-4.62.3-py2.py3-none-any.whl\n",
      "Collecting PyYAML>=5.1 (from -r requirements.txt (line 4))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting opencv-python==4.2.0.32 (from -r requirements.txt (line 5))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/34/a3/403dbaef909fee9f9f6a8eaff51d44085a14e5bb1a1ff7257117d744986a/opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting decord==0.4.2 (from -r requirements.txt (line 6))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c0/0c/7d99cfcde7b85f80c9ea9b0b19441339ad3cef59ee7fa5386598db714efe/decord-0.4.2-py2.py3-none-manylinux1_x86_64.whl\n",
      "Collecting av==8.0.3 (from -r requirements.txt (line 7))\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n",
      "Building wheels for collected packages: pandas\n",
      "  Building wheel for pandas (PEP 517) ... \u001b[?25l/^C\n",
      "\u001b[?25canceled\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\r\n",
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 测试脚本\n",
    "模型训练完成后，可使用测试脚本进行评估，\n",
    "\n",
    "### 测试脚本启动命令\n",
    "```bash\n",
    "bash inference.sh\n",
    "```\n",
    "\n",
    "- 评估结果保存在`final_submission.csv`文件中，可在[评测官网](https://aistudio.baidu.com/aistudio/competition/detail/115)提交查看得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.71it/s]\n",
      "100%|█████████████████████████████████████| 2499/2499 [00:00<00:00, 2791.89it/s]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 17, in <module>\n",
      "    from paddlevideo.tasks import train_model, train_model_multigrid, test_model, train_dali\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/__init__.py\", line 15, in <module>\n",
      "    from .train import train_model\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/train.py\", line 23, in <module>\n",
      "    from ..loader.builder import build_dataloader, build_dataset\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/__init__.py\", line 15, in <module>\n",
      "    from .builder import build_dataset, build_dataloader, build_batch_pipeline\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/builder.py\", line 20, in <module>\n",
      "    from .pipelines.compose import Compose\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/__init__.py\", line 20, in <module>\n",
      "    from .decode import VideoDecoder, FrameDecoder\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/decode.py\", line 16, in <module>\n",
      "    import av\n",
      "ModuleNotFoundError: No module named 'av'\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 17, in <module>\n",
      "    from paddlevideo.tasks import train_model, train_model_multigrid, test_model, train_dali\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/__init__.py\", line 15, in <module>\n",
      "    from .train import train_model\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/train.py\", line 23, in <module>\n",
      "    from ..loader.builder import build_dataloader, build_dataset\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/__init__.py\", line 15, in <module>\n",
      "    from .builder import build_dataset, build_dataloader, build_batch_pipeline\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/builder.py\", line 20, in <module>\n",
      "    from .pipelines.compose import Compose\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/__init__.py\", line 20, in <module>\n",
      "    from .decode import VideoDecoder, FrameDecoder\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/decode.py\", line 16, in <module>\n",
      "    import av\n",
      "ModuleNotFoundError: No module named 'av'\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 17, in <module>\n",
      "    from paddlevideo.tasks import train_model, train_model_multigrid, test_model, train_dali\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/__init__.py\", line 15, in <module>\n",
      "    from .train import train_model\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/tasks/train.py\", line 23, in <module>\n",
      "    from ..loader.builder import build_dataloader, build_dataset\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/__init__.py\", line 15, in <module>\n",
      "    from .builder import build_dataset, build_dataloader, build_batch_pipeline\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/builder.py\", line 20, in <module>\n",
      "    from .pipelines.compose import Compose\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/__init__.py\", line 20, in <module>\n",
      "    from .decode import VideoDecoder, FrameDecoder\n",
      "  File \"/home/aistudio/work/ccf/paddlevideo/loader/pipelines/decode.py\", line 16, in <module>\n",
      "    import av\n",
      "ModuleNotFoundError: No module named 'av'\n",
      "Traceback (most recent call last):\n",
      "  File \"ensemble.py\", line 13, in <module>\n",
      "    r1 = open('joint_score.pkl', 'rb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'joint_score.pkl'\n"
     ]
    }
   ],
   "source": [
    "#启动预测脚本指令\r\n",
    "!bash inference.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "测试脚本运行完成后，可以在当前目录中得到`submission.csv`文件，将该文件提交至[评测官网](https://aistudio.baidu.com/aistudio/competition/detail/115)，即可以查看在A榜得分。示例给出的模型文件，在A榜的得分为59.07。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
